{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.5.pdf', '5.6.pdf', 'HR-dataset.csv.xls', '.ipynb_checkpoints', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#F1A424'>5.7. Практика</span></b> \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            font-size:150%;background-image: url(https://i.imgur.com/ohv2A06.png);\n",
    "            letter-spacing:1.0px\">\n",
    "    <p style=\"padding: 12px;color:white;\"><b><span style='color:#F1A424'>\n",
    "        Задание</span> </b></p></div>\n",
    "\n",
    "- Разберёмся с `ансамблями алгоритмов` и со случайным лесом\n",
    "- Рассмотрим данные о сотрудниках компании, где указывается, **ушёл сотрудник или нет** (Задача бинарной классификации)\n",
    "\n",
    "**<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">Базовая предобработка</mark>**\n",
    "\n",
    "- удалим признак, который отвечает за идентификатор пользователя как нерепрезетативный признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
      "       'average_montly_hours', 'time_spend_company', 'Work_accident',\n",
      "       'promotion_last_5years', 'dept', 'salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('HR-dataset.csv.xls')\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Целевой признак\n",
    "target = 'left'\n",
    "features = df.columns.drop(target)\n",
    "\n",
    "# Удалим идентификатор пользователя как нерепрезентативный признак\n",
    "features = features.drop('empid')  \n",
    "print(features)\n",
    "\n",
    "# Распределяем фичеры\n",
    "X, y = df[features].copy(), df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">Предобработка</mark>**\n",
    "\n",
    "`Частотное кодирование`\n",
    "- Заменим идентификатор отдела `dept`, к которому относился сотрудник, на количество людей в отделе\n",
    "\n",
    "`Ординальноге кодирование`\n",
    "\n",
    "- Зарплату `salary` — на ординальную категорию, используя `salary_ordinals`\n",
    "\n",
    "\n",
    "- **Масштабируем** признаки для последующего сравнения результатов с помошью `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappers\n",
    "salary_ordinals = {'low': 1, 'medium': 2, 'high': 3}\n",
    "dept_val_counts = X['dept'].value_counts()\n",
    "\n",
    "X['dept'] = X['dept'].map(dept_val_counts)\n",
    "X['salary'] = X['salary'].map(salary_ordinals)\n",
    "# X = X.copy()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(data=scaler.fit_transform(X), \n",
    "                 columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">Оценка качества модели</mark>**\n",
    "\n",
    "Как будем оценивать качество модели?\n",
    "\n",
    "В дальнейшем будем оценивать качество модели\n",
    "- на **кросс-валидации** \n",
    "- на пяти фолдах при помощи **точности** (`accuracy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(clf, X, y, cv=5):\n",
    "    return cross_val_score(clf, X, y, cv=5, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бэггинг\n",
    "- Bootstrap aggregating\n",
    "- Mетод построения композиции алгоритмов, в котором каждый алгоритм строится независимо от других на подвыборках обучающей выборки\n",
    "- Итоговый алгоритм принимает решения посредством голосования среди всех алгоритмов (возвращается самый частый ответ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Посмотрим на точность **одного дерева решении** с **максимальной глубиной** 30\n",
    "- Проведём `бэггинг` : для этого достаточно **обернуть исходный классификатор** в `BaggingClassifier`\n",
    "- **Композиция отдельных деревьев** показывает себя лучше, чем одно дерево (0.94 -> 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.9450045314500757\n",
      "Decision tree bagging: 0.9745837353643367\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=30)\n",
    "print(\"Decision tree:\", estimate_accuracy(tree, X, y))\n",
    "\n",
    "bagging_trees = BaggingClassifier(tree)\n",
    "print(\"Decision tree bagging:\", estimate_accuracy(bagging_trees, X, y))\n",
    "\n",
    "#  Это явно улучшает результат не только беггинга но модель одного дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приемущество бэггинг\n",
    "\n",
    "Структура дерева серьёзно зависит от **обучающей выборки**\n",
    "- Это значит, что если немного изменить обучающую выборку, то **дерево сильно изменится**\n",
    "- Kомпозиция алгоритмов **при помощи голосования** работает наилучшим образом, когда модели различны\n",
    "- Увеличить **различность построенных деревьев** можно, указав параметры `max_features` и `max_depth`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3\n",
      "Random tree: 0.9540713833978115\n",
      "Random tree bagging: 0.9791073387690844\n"
     ]
    }
   ],
   "source": [
    "mfeats = int(np.sqrt(len(features)))\n",
    "print(f'Number of features: {mfeats}')\n",
    "\n",
    "random_tree = DecisionTreeClassifier(max_features=mfeats,\n",
    "                                     max_depth=30)\n",
    "print(\"Random tree:\", estimate_accuracy(random_tree, X, y))\n",
    "\n",
    "bagging_random_trees = BaggingClassifier(random_tree)\n",
    "print(\"Random tree bagging:\", estimate_accuracy(bagging_random_trees, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Именно так внутри и работает так называемый **<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">случайный лес</mark>**\n",
    "\n",
    "Oн **обучает набор деревьев** (`n_esimators`), каждое из которых:\n",
    " \n",
    " - **обучается на подмножестве признаков** **<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">Random Subspaces</mark>**\n",
    " - и **на подмножестве объектов** **<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">Bootstrap</mark>** \n",
    "    \n",
    "    \n",
    "То есть **случайный лес** получается случайным по двум этим параметрам\n",
    "- а **ответы аггрегируются** при помощи **голосования**\n",
    "\n",
    "\n",
    "Стандартная эвристика: \n",
    "- в задаче классификации брать **квадратный корень числа признаков**, задаче регрессии — **треть числа признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.9829834277014811\n"
     ]
    }
   ],
   "source": [
    "mfeats = int(np.sqrt(len(features)))\n",
    "random_forest = RandomForestClassifier(n_estimators=100,\n",
    "                                       n_jobs=-1,\n",
    "                                       max_features=mfeats,\n",
    "                                       max_depth=30)\n",
    "print(\"Random Forest:\", estimate_accuracy(random_forest, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё одно преимущество использования **беггинга для аггрегации моделей**\n",
    "\n",
    "Получение оценки работы классиф. без дополнительного проведения CV\n",
    "- при помощи **обучается на подмножестве признаков** **<mark style=\"background-color:#F1C40F;color:white;border-radius:5px;opacity:0.9\">out-of-bag score\n",
    "</mark>**\n",
    "\n",
    "- Это метод вычисления произвольной оценки качества во время обучения беггинга\n",
    "- Для подсчёта требуется указать параметр **`oob_score = True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929995333022201"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfeats = int(np.sqrt(len(features)))\n",
    "random_forest = RandomForestClassifier(n_estimators=100,\n",
    "                                       max_features=mfeats,\n",
    "                                       max_depth=30,\n",
    "                                       oob_score=True,\n",
    "                                       n_jobs=-1)\n",
    "random_forest.fit(X, y)\n",
    "random_forest.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бэггинг для линейных моделей \n",
    "\n",
    "Метод **беггинга** можно применять к произвольным алгоритмам, например, к **логистической регрессии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.44172459802488306\n",
      "Bagging for LR: 0.4365451576623669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LogisticRegression(solver='saga', \n",
    "                        max_iter=200)\n",
    "lr.fit(X, y)\n",
    "print(\"LR:\", estimate_accuracy(lr, X, y))\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "random_logreg = BaggingClassifier(lr,\n",
    "                                  n_estimators=10,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=42)\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В её случае он не так сильно повышает качество, поскольку **линейные модели не так сильно зависят от состава обучающей выборки**\n",
    "- Попробуем убрать часть признаков с помощью `max_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии:\n",
    "- повышение разнообразности моделей не дает такого прироста, как с деревьями, поскольку модели сильно теряют в качестве. \n",
    "- Случайный лес на примере нашей задачи справляется лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    " \n",
    "<br> \n",
    " \n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#15C3BA;text-align:center'>Наш Датасет</span></b></p></div>\n",
    "        \n",
    "- Загрузите датасет digits с помощью функции `load_digits` из sklearn.datasets и подготовьте матрицу признаков  и ответы на обучающей выборке (вам потребуются поля data и target в объекте, который возвращает load_digits) \n",
    "- Информацию о датасете вы можете получить, обратившись к полю `DESCR` у возвращаемого объекта load_digits. Нам предстоит решать **задачу классификации изображений с цифрами по численным признакам**\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#15C3BA;text-align:center'>Оценка Качества</span></b></p></div>\n",
    "\n",
    "- Для **оценки качества** мы будем использовать cross_val_score из sklearn.model_selection с параметром . Эта функция реализует k-fold cross validation c  равным значению параметра . Предлагается использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет  чисел — качество в каждом из  экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает `cross_val_score`\n",
    "\n",
    "\n",
    "- С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадёт в диапазон, заданный для правильных ответов — в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
    "- Чтобы ускорить вычисление `cross_val_score`, следует попробовать использовать параметр n_jobs. Число, которое вы подаёте в качестве этого параметра, соответствует количеству потоков вашего процессора, которое будет задействовано в вычислении.\n",
    "\n",
    "        \n",
    "### <b>Задание <span style='color:#F1A424'>5.7.1</span></b> \n",
    "\n",
    "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X = pd.DataFrame(data=scaler.fit_transform(X), \n",
    "#                  columns=digits.feature_names)\n",
    "features = digits.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tree: 0.823032278088144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "def estimate_accuracy(clf, X, y, cv=10):\n",
    "    return cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "random_tree = DecisionTreeClassifier()\n",
    "print(\"Random tree:\", estimate_accuracy(random_tree, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.2</span></b> \n",
    "\n",
    "- Теперь давайте обучим `BaggingClassifier` на основе `DecisionTreeClassifier`\n",
    "- Из sklearn.ensemble импортируйте `BaggingClassifier`, все параметры задайте по умолчанию\n",
    "- Нужно изменить только количество **базовых моделей**, задав его равным **100**\n",
    "- Подумайте, какие выводы можно сделать из соотношения качества **одиночного дерева** и **беггинга деревьев**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Bag: 0.9214990689013035\n"
     ]
    }
   ],
   "source": [
    "def estimate_accuracy(clf, X, y, cv=10):\n",
    "    return cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "# Количество базовых моделей 100\n",
    "bagging_random_trees = BaggingClassifier(random_tree,\n",
    "                                         n_estimators=100)\n",
    "print(\"Random Tree Bag:\", estimate_accuracy(bagging_random_trees,\n",
    "                                                X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.3</span></b> \n",
    "\n",
    "Теперь изучите параметры `BaggingClassifier` и выберите их такими\n",
    "- Чтобы каждый **базовый алгоритм** обучался не на всех **d** признаках, а на **sqrt(d)** случайных признаках\n",
    "\n",
    "Корень из числа признаков - часто используемая эвристика в задачах классификации\n",
    "- В задачах регрессии же часто берут число признаков, деленное на три, **log(d)** тоже имеет место быть\n",
    "\n",
    "\n",
    "Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков, добиваясь лучшего качества на **кросс-валидации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-1246f9e7730f>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-1246f9e7730f>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    decision_tree = DecisionTreeClassifier(max_depth = 10)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "def estimate_accuracy(clf, X, y, cv=10):\n",
    "    return cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "mfeats = int(np.sqrt(len(features))\n",
    "decision_tree = DecisionTreeClassifier(max_depth = 10)\n",
    "    \n",
    "print(\"Decision Tree:\", estimate_accuracy(decision_tree,X,y))\n",
    "\n",
    "bagging_random_trees = BaggingClassifier(decision_tree,\n",
    "                                         n_estimators=100,\n",
    "                                         max_features=mfeats,\n",
    "                                         random_state=42)\n",
    "\n",
    "print(\"Random Tree Bag:\", estimate_accuracy(bagging_random_trees,X,y))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.4</span></b> \n",
    "\n",
    "- В предыдущем пункте мы выбирали подмножество один раз для каждого очередного дерева\n",
    "- Следующим нашим шагом будет построение беггинга на основе деревьев, **которые выбирают случайное подмножество признаков** для каждой вершины дерева\n",
    "\n",
    "\n",
    "- Для этого нам потребуется перенести, отвечающий за это параметр из `BaggingClassifier` в `DecisionTreeClassifier` \n",
    "- Для этого вам из документации нужно выяснить, какой параметр `DecisionTreeClassifier` за это отвечает\n",
    "- По-прежнему сэмплируем `sqrt(d)` признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Decision Tree Arguments\n",
    "criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0\n",
    "'''\n",
    "\n",
    "'''\n",
    "BaggingClassifier Arguments\n",
    "base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfeats = int(np.log(len(features)))\n",
    "mfeats = int(np.sqrt(len(features)))\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(max_depth = 10)\n",
    "print(\"Decision Tree:\", estimate_accuracy(decision_tree,X,y))\n",
    "    \n",
    "bagging_random_trees = BaggingClassifier(base_estimator=random_tree,\n",
    "                                         random_state=22,\n",
    "                                         bootstrap_features=True,\n",
    "                                         n_jobs=-1)\n",
    "#                                          max_features=mfeats)\n",
    "    \n",
    "print(\"Random Tree Bag:\", estimate_accuracy(bagging_random_trees,X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.5</span></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

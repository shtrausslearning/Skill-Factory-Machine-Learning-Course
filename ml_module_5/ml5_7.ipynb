{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"padding: 50px;color:white;margin:10;font-size:80%;text-align:left;display:fill;border-radius:10px;background-color:#323232;overflow:hidden\"><b><span style='color:#F1A424'>(7/8) |</span></b> Практика</div>\n",
    "\n",
    "Разберёмся с `ансамблями` алгоритмов и со случайным лесом. Рассмотрим данные о сотрудниках компании, где указывается, ушёл сотрудник или нет, задача бинарной классификации.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>ИМПОРТИРУЕМ МОДУЛИ</span></b></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
      "       'average_montly_hours', 'time_spend_company', 'Work_accident',\n",
      "       'promotion_last_5years', 'dept', 'salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "df = pd.read_csv('HR-dataset.csv')\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "target = 'left'\n",
    "features = df.columns.drop(target)\n",
    "features = features.drop('empid')  # Удалим идентификатор пользователя как нерепрезентативный признак\n",
    "print(features)\n",
    "\n",
    "X, y = df[features].copy(), df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>ПРЕДОБРАБОТКА</span></b></p></div>\n",
    "\n",
    "`Частотное кодирование`\n",
    "- Заменим идентификатор отдела `dept`, к которому относился сотрудник, на количество людей в отделе\n",
    "\n",
    "`Ординальноге кодирование`\n",
    "\n",
    "- Зарплату `salary` — на ординальную категорию, используя `salary_ordinals`\n",
    "\n",
    "\n",
    "- **Масштабируем** признаки для последующего сравнения результатов с помошью `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# частотное кодирование\n",
    "dept_val_counts = X['dept'].value_counts()\n",
    "X['dept'] = X['dept'].map(dept_val_counts)\n",
    "\n",
    "# ординальное кодирование\n",
    "salary_ordinals = {'low': 1, 'medium': 2, 'high': 3}\n",
    "X['salary'] = X['salary'].map(salary_ordinals)\n",
    "# X = X.copy()\n",
    "\n",
    "# ьаштабируем данные\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(data=scaler.fit_transform(X), \n",
    "                 columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>ОЦЕНКА МОДЕЛИ</span></b></p></div>\n",
    "\n",
    "Как будем оценивать качество модели?\n",
    "\n",
    "В дальнейшем будем оценивать качество модели\n",
    "- на **кросс-валидации** (cross validation) `cross_val_score`\n",
    "- на пяти фолдах при помощи **f1 score** (`f1 меры`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def estimate_accuracy(clf, X, y, cv=5,metric='f1'):\n",
    "    cv_mean = cross_val_score(clf, X, y, cv=5, scoring=metric).mean()\n",
    "    return round(cv_mean,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>БЭГГИНГ (BAGGING)</span></b></p></div>\n",
    "\n",
    "- Bootstrap aggregating\n",
    "- Mетод построения `композиции алгоритмов`, в котором каждый алгоритм строится независимо от других `на подвыборках` обучающей выборки\n",
    "- `Итоговый алгоритм` принимает решения посредством `голосования` среди всех алгоритмов (возвращается самый частый ответ)\n",
    "- Обертование исходного класса (`BaggingClassifier(clf)`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Посмотрим на точность одного дерева решении с максимальной глубиной 30 (`max_depth=30`)\n",
    "- Проведём `бэггинг` : для этого достаточно обернуть исходный классификатор в `BaggingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.945\n",
      "Decision tree bagging: 0.975\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на точность одного дерева.\n",
    "tree = DecisionTreeClassifier(max_depth=30)\n",
    "print(\"Decision tree:\", estimate_accuracy(tree, X, y))\n",
    "\n",
    "# Проведём бэггинг: для этого достаточно обернуть исходный классификатор в BaggingClassifier.\n",
    "bagging_trees = BaggingClassifier(tree)\n",
    "print(\"Decision tree bagging:\", estimate_accuracy(bagging_trees, X, y))\n",
    "\n",
    "#  Это явно улучшает результат не только беггинга но модель одного дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Композиция` отдельных деревьев показывает себя лучше, чем одно дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>ПРИЕМУЩЕСТВО БЭГГИНГА (BAGGING)</span></b></p></div>\n",
    "\n",
    "Структура дерева серьёзно зависит от **обучающей выборки**\n",
    "- Это значит, что если немного изменить обучающую выборку, то **дерево сильно изменится**\n",
    "- Kомпозиция алгоритмов **при помощи голосования** работает наилучшим образом, когда модели различны\n",
    "- Увеличить **различность построенных деревьев** можно, указав параметры `max_features` и `max_depth`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3\n",
      "Random tree: 0.954\n",
      "Random tree bagging: 0.979\n"
     ]
    }
   ],
   "source": [
    "mfeats = int(np.sqrt(len(features)))\n",
    "print(f'Number of features: {mfeats}')\n",
    "\n",
    "random_tree = DecisionTreeClassifier(max_features=mfeats,\n",
    "                                     max_depth=30)\n",
    "print(\"Random tree:\", estimate_accuracy(random_tree, X, y))\n",
    "\n",
    "bagging_random_trees = BaggingClassifier(random_tree)\n",
    "print(\"Random tree bagging:\", estimate_accuracy(bagging_random_trees, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>СЛУЧАЙНЫЙ ЛЕС </span></b></p></div>\n",
    "\n",
    "Именно так внутри и работает так называемый `случайный лес`\n",
    "\n",
    "Oн обучает набор деревьев `n_esimators`, каждое из которых:\n",
    " \n",
    " - обучается на подмножестве признаков (`метод случайных подпространств`)\n",
    " - и на подмножестве объектов (`бэггинг`)\n",
    " - `случайный лес` получается случайным по двум этим параметрам\n",
    " - `ответы аггрегируются` при помощи `голосования`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.983\n"
     ]
    }
   ],
   "source": [
    "# Стандартная эвристика: \n",
    "# - в задаче классификации брать **квадратный корень числа признаков**, задаче регрессии — **треть числа признаков**\n",
    "\n",
    "mfeats = int(np.sqrt(len(features)))\n",
    "random_forest = RandomForestClassifier(n_estimators=100,\n",
    "                                       n_jobs=-1,\n",
    "                                       max_features=mfeats,\n",
    "                                       max_depth=30)\n",
    "print(\"Random Forest:\", estimate_accuracy(random_forest, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>OOB SCORE </span></b></p></div>\n",
    "\n",
    "Ещё одно преимущество использования \n",
    "беггинга для аггрегации моделей\n",
    "\n",
    "Получение оценки работы классификатора без дополнительного проведения `кросс-валидации`при помощи `out-of-bag` метрики\n",
    "\n",
    "Это метод вычисления произвольной оценки качества во время обучения беггинга\n",
    "Для подсчёта требуется указать параметр **`oob_score = True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfeats = int(np.sqrt(len(features)))\n",
    "random_forest = RandomForestClassifier(n_estimators=100,\n",
    "                                       max_features=mfeats,\n",
    "                                       max_depth=30,\n",
    "                                       oob_score=True,\n",
    "                                       n_jobs=-1)\n",
    "random_forest.fit(X, y)\n",
    "\n",
    "# тектируем модель на данных который алгоритм не использовал\n",
    "round(random_forest.oob_score_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>БЭГГИНГ ДЛЯ ЛОГИСТИЧЕСКОЙ РЕГРЕСИИ </span></b></p></div>\n",
    "\n",
    "Метод `бэггинга` можно применять к произвольным алгоритмам, например, к `логистической регрессии`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.442\n",
      "Bagging for LR: 0.437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "# базовый алгоритм\n",
    "lr = LogisticRegression(solver='saga', \n",
    "                        max_iter=200)\n",
    "lr.fit(X, y)\n",
    "print(\"LR:\", estimate_accuracy(lr, X, y))\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# бэггинг классификатор\n",
    "random_logreg = BaggingClassifier(lr,\n",
    "                                  n_estimators=10,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=42)\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему так?\n",
    "\n",
    "- В её случае он не так сильно повышает качество, поскольку `линейные` модели не так сильно зависят от состава обучающей выборки\n",
    "- Попробуем убрать часть признаков с помощью `max_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging for LR: 0.22\n"
     ]
    }
   ],
   "source": [
    "random_logreg = BaggingClassifier(\n",
    "    lr,\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1,\n",
    "    max_features=0.5,  # выбираем только часть фич\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии:\n",
    "- Повышение `разнообразности` моделей не дает такого прироста, как с деревьями, поскольку модели сильно теряют в качестве. \n",
    "- Случайный лес на примере нашей задачи справляется лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424'>ПРАКТИКА</span></b></p></div>\n",
    " \n",
    "#### датасет\n",
    "        \n",
    "- Загрузите датасет digits с помощью функции `load_digits` из sklearn.datasets\n",
    "- Нам предстоит решать задачу `классификации изображений` с цифрами по численным признакам\n",
    "\n",
    "#### оценка качества\n",
    "\n",
    "- Для **оценки качества** мы будем использовать `cross_val_score` из sklearn.model_selection с параметром . Эта функция реализует k-fold cross validation c  равным значению параметра . \n",
    "- Предлагается использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет  чисел — качество в каждом из  экспериментов k-fold cross validation.\n",
    "- Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает `cross_val_score`\n",
    "        \n",
    "### <b>Задание <span style='color:#F1A424'>5.7.1</span></b> \n",
    "\n",
    "Создайте `DecisionTreeClassifier` с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-0.043081</td>\n",
       "      <td>0.274072</td>\n",
       "      <td>-0.664478</td>\n",
       "      <td>-0.844129</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757436</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>0.086719</td>\n",
       "      <td>0.208293</td>\n",
       "      <td>-0.366771</td>\n",
       "      <td>-1.146647</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-1.094937</td>\n",
       "      <td>0.038648</td>\n",
       "      <td>0.268751</td>\n",
       "      <td>-0.138020</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757436</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>-1.089383</td>\n",
       "      <td>-0.249010</td>\n",
       "      <td>0.849632</td>\n",
       "      <td>0.548561</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-1.094937</td>\n",
       "      <td>-1.844742</td>\n",
       "      <td>0.735366</td>\n",
       "      <td>1.097673</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259230</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>-1.089383</td>\n",
       "      <td>-2.078218</td>\n",
       "      <td>-0.164037</td>\n",
       "      <td>1.565686</td>\n",
       "      <td>1.695137</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>0.377661</td>\n",
       "      <td>0.744919</td>\n",
       "      <td>0.268751</td>\n",
       "      <td>-0.844129</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>1.879691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072563</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>0.282736</td>\n",
       "      <td>0.208293</td>\n",
       "      <td>0.241430</td>\n",
       "      <td>0.379040</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-1.094937</td>\n",
       "      <td>-2.551014</td>\n",
       "      <td>-0.197863</td>\n",
       "      <td>-1.020657</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757436</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>-1.089383</td>\n",
       "      <td>-2.306869</td>\n",
       "      <td>0.849632</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0  -0.335016  -0.043081   0.274072  -0.664478  -0.844129   \n",
       "1        0.0  -0.335016  -1.094937   0.038648   0.268751  -0.138020   \n",
       "2        0.0  -0.335016  -1.094937  -1.844742   0.735366   1.097673   \n",
       "3        0.0  -0.335016   0.377661   0.744919   0.268751  -0.844129   \n",
       "4        0.0  -0.335016  -1.094937  -2.551014  -0.197863  -1.020657   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0  -0.409724  -0.125023  -0.059078  -0.624009  ...  -0.757436  -0.209785   \n",
       "1  -0.409724  -0.125023  -0.059078  -0.624009  ...  -0.757436  -0.209785   \n",
       "2  -0.409724  -0.125023  -0.059078  -0.624009  ...   0.259230  -0.209785   \n",
       "3  -0.409724  -0.125023  -0.059078   1.879691  ...   1.072563  -0.209785   \n",
       "4  -0.409724  -0.125023  -0.059078  -0.624009  ...  -0.757436  -0.209785   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0  -0.023596  -0.299081   0.086719   0.208293  -0.366771  -1.146647   \n",
       "1  -0.023596  -0.299081  -1.089383  -0.249010   0.849632   0.548561   \n",
       "2  -0.023596  -0.299081  -1.089383  -2.078218  -0.164037   1.565686   \n",
       "3  -0.023596  -0.299081   0.282736   0.208293   0.241430   0.379040   \n",
       "4  -0.023596  -0.299081  -1.089383  -2.306869   0.849632  -0.468564   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0  -0.505670  -0.196008  \n",
       "1  -0.505670  -0.196008  \n",
       "2   1.695137  -0.196008  \n",
       "3  -0.505670  -0.196008  \n",
       "4  -0.505670  -0.196008  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_view = pd.DataFrame(data=scaler.fit_transform(X), \n",
    "                       columns=digits.feature_names)\n",
    "features = digits.feature_names\n",
    "X_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tree: 0.782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "random_tree = DecisionTreeClassifier()\n",
    "print(\"Random tree:\", estimate_accuracy(random_tree, X, y,metric='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.2</span></b> \n",
    "\n",
    "- Теперь давайте обучим `BaggingClassifier` на основе `DecisionTreeClassifier`\n",
    "- Из sklearn.ensemble импортируйте `BaggingClassifier`, все параметры задайте по умолчанию\n",
    "- Нужно изменить только количество **базовых моделей**, задав его равным **100**\n",
    "- Подумайте, какие выводы можно сделать из соотношения качества **одиночного дерева** и **беггинга деревьев**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Bag: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Количество базовых моделей 100\n",
    "bagging_random_trees = BaggingClassifier(random_tree,\n",
    "                                         n_estimators=100)\n",
    "print(\"Random Tree Bag:\", estimate_accuracy(bagging_random_trees,\n",
    "                                                X, y,metric='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.3</span></b> \n",
    "\n",
    "Теперь изучите параметры `BaggingClassifier` и выберите их такими\n",
    "- Чтобы каждый **базовый алгоритм** обучался не на всех **d** признаках, а на **sqrt(d)** случайных признаках\n",
    "\n",
    "Корень из числа признаков - часто используемая эвристика в задачах классификации\n",
    "- В задачах `регрессии` же часто берут число признаков, деленное на три, **log(d)** тоже имеет место быть\n",
    "\n",
    "\n",
    "Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков, добиваясь лучшего качества на **кросс-валидации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.786\n",
      "bagging 8 features\n",
      "Random Tree Bag: 0.919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "# базовый коассификатор\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "print(\"Decision Tree:\", estimate_accuracy(decision_tree,X,y,metric='accuracy'))\n",
    "\n",
    "# Используем только часть признаков\n",
    "mfeats = int(np.sqrt(len(features)))\n",
    "print('bagging',mfeats,'features')\n",
    "      \n",
    "# Бэггинг классификатор\n",
    "bagging_random_trees = BaggingClassifier(decision_tree,\n",
    "                                         n_estimators=100,\n",
    "                                         max_features=mfeats,\n",
    "                                         random_state=42)\n",
    "\n",
    "print(\"Random Tree Bag:\", estimate_accuracy(bagging_random_trees,X,y,metric='accuracy'))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.4</span></b> \n",
    "\n",
    "- В предыдущем пункте мы _выбирали подмножество один раз для каждого очередного дерева_\n",
    "- Следующим нашим шагом будет построение беггинга на основе деревьев, **которые выбирают случайное подмножество признаков** для каждой вершины дерева\n",
    "\n",
    "\n",
    "- Для этого нам потребуется перенести, отвечающий за это параметр из `BaggingClassifier` в `DecisionTreeClassifier` \n",
    "- Для этого вам из документации нужно выяснить, какой параметр `DecisionTreeClassifier` за это отвечает\n",
    "- По-прежнему сэмплируем `sqrt(d)` признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBaggingClassifier Arguments\\nbase_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Decision Tree Arguments\n",
    "criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0\n",
    "'''\n",
    "\n",
    "'''\n",
    "BaggingClassifier Arguments\n",
    "base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging 8 features\n",
      "Decision Tree: 0.782\n",
      "Random Tree Bag: 0.914\n"
     ]
    }
   ],
   "source": [
    "# mfeats = int(np.log(len(features)))\n",
    "mfeats = int(np.sqrt(len(features)))\n",
    "print('bagging',mfeats,'features')    \n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "# decision_tree = DecisionTreeClassifier(max_features=mfeats)\n",
    "print(\"Decision Tree:\", estimate_accuracy(decision_tree,X,y,metric='accuracy'))\n",
    "    \n",
    "bagging_random_trees = BaggingClassifier(base_estimator=decision_tree,\n",
    "                                         n_estimators=100,\n",
    "                                         n_jobs=-1,\n",
    "                                         random_state=42)\n",
    "    \n",
    "print(\"Random Tree Bag:\", estimate_accuracy(bagging_random_trees,X,y,metric='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Задание <span style='color:#F1A424'>5.7.5</span></b> \n",
    "\n",
    "- Полученный в задании 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним).\n",
    "- Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble.\n",
    "-Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева.\n",
    "- Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "gs = GridSearchCV(model,{'n_estimators':[5,10,15,20,25,30,35,40,45,50]})\n",
    "gs.fit(X,y)\n",
    "results = gs.cv_results_\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "валидационная \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{5: 0.8698050139275765,\n",
       " 10: 0.9048808418446301,\n",
       " 15: 0.9237790157845869,\n",
       " 20: 0.9243376663571649,\n",
       " 25: 0.9304642525533892,\n",
       " 30: 0.9332389353141443,\n",
       " 35: 0.9326864747756114,\n",
       " 40: 0.9310182606004334,\n",
       " 45: 0.9338037759207676,\n",
       " 50: 0.9349117920148562}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('валидационная ')\n",
    "dict(zip([i for i in range(5,55,5)],results['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- При очень маленьком числе деревьев (5, 10, 15) случайный лес работает хуже, чем при большем числе деревьев\n",
    "- С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "- При большом количестве признаков (для данного датасета - 40-50) качество классификации становится хуже, чем при малом количестве признаков (10-15). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "валидационная \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{5: 0.9009594552770039,\n",
       " 10: 0.9321324667285671,\n",
       " 15: 0.9343562364593005,\n",
       " 20: 0.937137109254101,\n",
       " 25: 0.9421417517796348,\n",
       " 30: 0.937137109254101,\n",
       " 35: 0.9382497678737233,\n",
       " 40: 0.9421417517796348,\n",
       " None: 0.9382513153822346}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "gs = GridSearchCV(model,{'max_depth':[5,10,15,20,25,30,35,40,None]})\n",
    "gs.fit(X,y)\n",
    "results = gs.cv_results_\n",
    "\n",
    "print('валидационная ')\n",
    "param_vals = [i for i in range(5,45,5)]\n",
    "param_vals.append(None)\n",
    "dict(zip(param_vals,results['mean_test_score'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. \n",
    "- С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг друга).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

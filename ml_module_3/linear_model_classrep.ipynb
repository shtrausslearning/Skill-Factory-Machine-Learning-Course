{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUQKRKfexr-R"
      },
      "source": [
        "# **Линейная/Логистическая Регрессия**\n",
        "\n",
        "## **<span style='color:#F1A424'>Реализация Классного Представления</span>**\n",
        "\n",
        "Реализуем регуляризацию в линейную модель\n",
        "\n",
        "- Для борьбы с переобучением добавим регуляризацию\n",
        "- **Сначала обернём линейную регрессию в классовое представление** (В этом ноутбуке)\n",
        "- Потом добавим вариант с регуляризации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8f14KzPxr-U"
      },
      "source": [
        "### **Общая Функция Градиентного Спуска**\n",
        "\n",
        "- Добавим то что мы добавили ранее в классовую форму\n",
        "- `regOptimiser` добавляем общие функции которые используются как и в регрессии так и в классификации с градиентным спуском\n",
        "\n",
        "Пройдемся по компонентам общего класса:\n",
        "- <code>gradient_step</code> - функция шага градиентного спуска\n",
        "- <code>optimize</code> - функция для обновления гипертараметра theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BGKZYvX-xr-U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class regOpt():\n",
        "\n",
        "    # initialisation\n",
        "\n",
        "    def __init__(self, alpha, n_iters):\n",
        "        self.theta = None\n",
        "        self._alpha = alpha\n",
        "        self._n_iters = n_iters\n",
        "\n",
        "    # gradient step\n",
        "\n",
        "    def gradient_step(self, theta, theta_grad):\n",
        "        return theta - self._alpha * theta_grad\n",
        "\n",
        "    # gradient function\n",
        "\n",
        "    def grad_func(self, X, y, theta):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    # optimisation process of theta\n",
        "\n",
        "    def optimize(self, X, y, start_theta, n_iters):\n",
        "\n",
        "        # theta_0\n",
        "        theta = start_theta.copy()\n",
        "\n",
        "        for _ in range(n_iters):\n",
        "            theta_grad = self.grad_func(X, y, theta)\n",
        "            theta = self.gradient_step(theta, theta_grad)\n",
        "\n",
        "        return theta\n",
        "\n",
        "    # Тренируем модель\n",
        "    def fit(self, X, y):\n",
        "        m = X.shape[1]\n",
        "        start_theta = np.ones(m)\n",
        "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
        "\n",
        "    # Делаем предсказание\n",
        "    def predict(self, X):\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vqDYVtYxr-W"
      },
      "source": [
        "### **Дочерний Класс для Регрессии**\n",
        "\n",
        "Отличие регрессии и классификации только в методах\n",
        "- <code>grad_func</code> - функция для dL/dtheta\n",
        "- <code>predict</code> - функция для предсказания\n",
        "\n",
        "Для линейной регрессии нам нужно создать дочерний класс <code>LinReg</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OsVrPwGsxr-W"
      },
      "outputs": [],
      "source": [
        "# linReg будет иметь доступ к функции из regOptimiser\n",
        "class LinReg(regOpt):\n",
        "\n",
        "    # для линейной регресии у нас функция потерь\n",
        "    def grad_func(self, X, y, theta):\n",
        "        n = X.shape[0]\n",
        "        grad = 1.0 / n * X.T.dot(X.dot(theta) - y)\n",
        "        return grad\n",
        "\n",
        "    # для линейной регрессии предсказание X.theta\n",
        "    def predict(self, X):\n",
        "        if(self.theta is None):\n",
        "            raise Exception('You should train the model first')\n",
        "\n",
        "        y_pred = X.dot(self.theta)\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим модель на примере предсказания стоимости жилья в Бостоне (задача регрессии)"
      ],
      "metadata": {
        "id": "3trcUx9p4CQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTUxA-q3xr-X",
        "outputId": "8bfecb99-bf41-4d09-f16c-ad90462f32b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE = 19.64, RMSE = 4.43\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Функци для определения RMSE\n",
        "def print_regression_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
        "\n",
        "# Функуия для предобработки & подготовки X,y\n",
        "def prepare_boston_data():\n",
        "    df = pd.read_csv('data.csv')\n",
        "    y = df['medv']\n",
        "    X = df.drop(['medv'],axis=1)\n",
        "\n",
        "    # Нормализовать даннные с помощью стандартной нормализации\n",
        "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
        "    X = np.hstack([np.ones(X.shape[0])[:,None], X])\n",
        "    return X, y\n",
        "\n",
        "# Иницилизируем линейной регрессии с alpha = 0.01, 500 итерации\n",
        "linreg = LinReg(0.01, 500)\n",
        "\n",
        "# Разбиваем выборку на тренировочную и валидационную выборку\n",
        "X, y = prepare_boston_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Тренируем модель на train выборке\n",
        "linreg.fit(X_train, y_train)\n",
        "\n",
        "# Предсказываем и оцениваем качество модели на валидационной выборке\n",
        "y_pred = linreg.predict(X_valid)\n",
        "print_regression_metrics(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtjMsChBxr-X"
      },
      "source": [
        "### **Дочерний Класс для Классификации**\n",
        "\n",
        "Отличие регрессии и классификации только в методах\n",
        "- <code>grad_func</code> - функция для dL/dtheta\n",
        "- <code>predict</code> - функция для предсказания (threshold = 0.5)\n",
        "- <code>predict_proba</code> - функция для распределения вероятностей принадлежности классу"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "class LogReg(regOpt):\n",
        "\n",
        "    def sigmoid(self, X, theta):\n",
        "        return 1.0 / (1.0 + np.exp(-X.dot(theta)))\n",
        "\n",
        "    # отличие только в self.sigmoid(X, theta)\n",
        "    def grad_func(self, X, y, theta):\n",
        "        n = X.shape[0]\n",
        "        grad = 1.0 / n * X.T.dot(self.sigmoid(X, theta) - y)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    # Вероятность принадлежности класса (0/1)\n",
        "    def predict_proba(self, X):\n",
        "        return self.sigmoid(X, self.theta)\n",
        "\n",
        "    # Предсказание с порогом 0.5\n",
        "    def predict(self, X):\n",
        "        if self.theta is None:\n",
        "            raise Exception('You should train the model first')\n",
        "\n",
        "        y_pred = self.predict_proba(X) > 0.5\n",
        "\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "BY2wRdJR1dod"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим модель на примере предсказания клссификации доходов (задача бирарной классификации)"
      ],
      "metadata": {
        "id": "0_pqORO74VPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_logisitc_metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')\n",
        "\n",
        "def prepare_adult_data():\n",
        "\n",
        "    adult = pd.read_csv('adult.data',\n",
        "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
        "                               'education-num', 'marital-status', 'occupation',\n",
        "                               'relationship', 'race', 'sex', 'capital-gain',\n",
        "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
        "\n",
        "    # Избавиться от лишних признаков\n",
        "    adult.drop(['native-country'], axis=1, inplace=True)\n",
        "    # Сконвертировать целевой столбец в бинарные значения\n",
        "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
        "    # Сделать one-hot encoding для некоторых признаков\n",
        "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status',\n",
        "                                           'occupation', 'relationship', 'race', 'sex'])\n",
        "\n",
        "    # Нормализовать нуждающиеся в этом признаки\n",
        "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
        "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
        "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
        "\n",
        "    # Разбить таблицу данных на матрицы X и y\n",
        "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
        "    y = adult['salary'].values\n",
        "\n",
        "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
        "    X = np.hstack([np.ones(X.shape[0])[:,None], X])\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "Q7H5dZjJ39cd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogReg(1.0, 300)\n",
        "X, y = prepare_adult_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Разбить выборку на train/valid, оптимизировать theta,\n",
        "# сделать предсказания и посчитать ошибку F1-score\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_valid)\n",
        "print_logisitc_metrics(y_valid, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EMnNKqg4qpE",
        "outputId": "f3ed8ac5-eecf-4f4e-c589-e0459ca506eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc = 0.85 F1-score = 0.66\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}